---
tags:
  - 知识
---
![[Pasted image 20250903164220.png]]
## 注意力机制

根据输入X计算QKV：设向量个数为3，初始维度为1000，最终输出维度为64
$$
X \in \mathbb{R}^{3 \times 1000}
$$
$$
    Q = XW_Q, \ \ \in \mathbb{R}^{3 \times 64}
$$
$$
K = XW_K, \ \ \in \mathbb{R}^{3 \times 64}
$$
$$
V = XW_V \ \ \in \mathbb{R}^{3 \times 64}
$$
计算注意力分数：除以根号d（缩放因子），控制点积的数值范围，提升数值稳定性，防止梯度消失爆炸。
$$
scores = \frac{QK^T}{\sqrt{d_k}} \ \ \in \mathbb{R}^{3 \times 3}
$$
对注意力分数做softmax(分值变概率)计算注意力权重：
$$
att_w = softmax(scores) \ \ \in \mathbb{R}^{3 \times 3}
$$
为V的一条特征向量的每个值赋予同一个注意力权重，不同特征向量有不同的注意力权重：
$$
output = att_w × V \ \ \in \mathbb{R}^{3 \times 64}
$$

**注意**：注意力的(QK)和V来自不同矩阵，而自注意力，QKV均来自同一个矩阵。
![[Pasted image 20250902181747.png]]

**多头**：把特征的特征维度根据头数均分，每个头独立计算注意力，最终把3个头的输出拼接起来。
- 不要对初始特征均分，这样计算出来QKV会失去部分特征信息。需要在得出QKV对QKV切。
- 作用是多头并行训练，其中一个头跑太偏带来的影响会被稀释。
- 不同的头手收敛出不同的最优解，提供多样性。

```Python
import torch
import torch.nn as nn

# 输入参数
num_heads = 4
input_dim = 1000
output_dim = 64
head_dim = output_dim // num_heads  # 每个头的维度
  
# 输入特征
X = torch.randn(3, input_dim)  # X ∈ ℝ^{3×1000}
  
# 多头线性变换
W_q = nn.Linear(input_dim, output_dim)
W_k = nn.Linear(input_dim, output_dim)
W_v = nn.Linear(input_dim, output_dim)

# 线性变换
Q = W_q(X)  # Q ∈ ℝ^{3×64}
K = W_k(X)  # K ∈ ℝ^{3×64}
V = W_v(X)  # V ∈ ℝ^{3×64}

# 分头
def split_heads(x, num_heads, head_dim):
    # x: [batch, output_dim] -> [batch, num_heads, head_dim]
    return x.view(x.size(0), num_heads, head_dim)

Q = split_heads(Q, num_heads, head_dim)  # [3, 4, 16]
K = split_heads(K, num_heads, head_dim)  # [3, 4, 16]
V = split_heads(V, num_heads, head_dim)  # [3, 4, 16]
  
# 转换为 [num_heads, batch, head_dim] 方便计算
Q = Q.transpose(0, 1)  # [4, 3, 16]
K = K.transpose(0, 1)  # [4, 3, 16]
V = V.transpose(0, 1)  # [4, 3, 16]

# 计算每个头的注意力
outputs = []
for i in range(num_heads):
    q = Q[i]  # [3, 16]
    k = K[i]  # [3, 16]
    v = V[i]  # [3, 16]
    scores = torch.matmul(q, k.T) / (head_dim ** 0.5)  # [3, 3]
    attn_weights = torch.softmax(scores, dim=1)        # [3, 3]
    out = torch.matmul(attn_weights, v)                # [3, 16]
    outputs.append(out)
  
# 拼接所有头的输出
output = torch.cat(outputs, dim=-1)  # [3, 64]
```

**Mask**：

![[Pasted image 20250902180517.png]]

## norm

1. batchnorm：假设batch为32，特征矩阵为3\*64，其中64为特征维度，一共3条特征向量。将会对所有batch的同一列做norm（不同特征向量的同一特征维度），即对32\*3个数据做norm，一共做64次。**对不同特征维度向量做norm**。
2. layernorm：假设特征矩阵为3\*64，其中64为特征维度，一共3条特征向量。将会对每一行的64个数据做norm（同一特征向量的不同特征维度），一共做3次。**对特征维度自身做norm**。